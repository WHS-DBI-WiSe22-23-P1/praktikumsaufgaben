Um die Ausführung der Statements zu beschleunigen, gibt es zwei Möglichkeiten: Performanteren Code oder eine Performanteres DBMS~. Im Folgenden sind zu beiden Möglichkeiten unsere Ansätze aufgeführt.

\subsection{Code}\label{subsec:code}
Schauen wir uns die 4 Methoden an, das Erstellen der Datenbanken, das Einfügen der Branches, das Einfügen der Accounts und das Einfügen der Automaten, so fällt schnell auf, dass keine der anderen Operationen einen signifikanten Zeitaufwand im Verhältnis zum Einfügen der Accounts benötigt.
Aus diesem Grund werden sich unsere Bemühungen bezüglich der Optimierungen im Code auf diese Teilaufgabe beziehen.
Hier ist uns vor allem eine Stellschraube in den Sinn gekommen: Die Anzahl der Statements.
Dazu haben wir zwei Möglichkeiten gefunden:
\begin{itemize}
    \item Das einfügen mehrerer Tupel mit einem Statement sowie
    \item das ausführen mehrerer Teilstatements in einem Statement (Batching).
\end{itemize}
Für n=1, also 100\_000 Tupel, sind die Messungen mit einer Logarithmischen Skala in Abbildung~\ref{fig:merged-statements-graph} dargestellt.
\begin{figure}[h!]
    \begin{tikzpicture}[baseline]
        \begin{axis}
        [
            small,
            width=\paperwidth/4,
            title={INSERT Statements},
            xlabel={Tupel pro Statement},
            ylabel={Zeit},
            y unit=\si{\second},
            scale only axis,
            xtick={1,10,100,1000,10000,100000},
            ytick={3,7,41,176,1647},
            yticklabels={3,7,41,176,1\_647},
            xmajorgrids,
            ymajorgrids,
            xmin=1,
            xmax=100000,
            ymin=0,
            ymax=2000,
            xmode=log,
            ymode=log,
        ]

            \addplot[only marks] table [
            mark=*,
            col sep=semicolon,
            x={duffConstant},
            y={time},
            ]
                {duff_messungen.csv};

            \addplot[thick, red] table [
            col sep=semicolon,
            x={duffConstant},
            y={time},
            y = {create col/linear regression={xmode=log,ymode=log, y={time},x={duffConstant}}},
            ]
                {duff_messungen.csv};
            \addlegendentry{$\log{y}=\pgfmathprintnumber{\pgfplotstableregressiona} \cdot \log{x} \pgfmathprintnumber[print sign]{\pgfplotstableregressionb}$}
        \end{axis}
    \end{tikzpicture}%
    \begin{tikzpicture}[baseline]
        \begin{axis}
        [
            small,
            width=\paperwidth/4,
            title={Batches},
            xlabel={Tupel pro Statement},
            ylabel={Zeit},
            y unit=\si{\second},
            scale only axis,
            xtick={1,10,100,1000,10000,100000},
            ytick={150,300,1500,2000},
            yticklabels={150,300,1\_500,2\_000},
            xmajorgrids,
            ymajorgrids,
            xmin=1,
            xmax=100000,
            ymin=0,
            ymax=2000,
            xmode=log,
            ymode=log,
            legend style={at={(0.97,0.6)},anchor=east}
        ]

            \addplot[only marks, blue] table [
            mark=*,
            col sep=semicolon,
            x={tupelsPerBatch},
            y={time},
            ]
                {batch_messungen.csv};
            \addlegendentry{Mit Autocommit}

            \addplot[only marks, green] table [
            mark=*,
            col sep=semicolon,
            x={tupelsPerBatch},
            y={time},
            ]
                {batch_no_autocommit_messungen.csv};
            \addlegendentry{Ohne Autocommit}
        \end{axis}
    \end{tikzpicture}
    \caption{Messungen bei unterteilung in verschieden viele Statements}
    \label{fig:merged-statements-graph}
\end{figure}
Schauen wir uns zunächst die Variante mit den vereinten INSERT Statements an, so fällt uns auf, dass die Messwerte annähernd auf der logarithmischen Annäherung liegen.
Desto weniger Statements, desto schneller ist das Programm.
Im Vergleich dazu ist bei den Batches keine Konsistenz in den Messwerten zu erkennen.
Da jede Messung über 20 Minuten gedauert hat, verzichten wir auf eine erneute Messung und schließen, dass beim Batching lediglich ein kleiner Vorteil, unabhängig der Anzahl der Batches, entsteht.
Es sind also die Commits, die Zeit benötigen.
Deaktivieren wir AutoCommit so läuft auch die Variante mit Batching deutlich schneller, auch wenn sie dennoch nicht mit den einzelnen Statements mithalten kann.
In diesem spezifischen Fall wollen wir uns also auf INSERT Statements mit vielen Tupeln festlegen.


\paragraph{Da} wir nun die Methodik kennen wollen wir uns ans Multithreading wagen.
\begin{figure}[h!]
    \center
    \begin{tikzpicture}[baseline]
        \begin{axis}
        [
            small,
            xlabel={n},
            ylabel={Zeit},
            y unit=\si{\second},
            scale only axis,
            xtick={1,10,20,50},
            ytick={3,4,32,44,61,84,195,295},
            yticklabels={,4,,44,,84,195,295},
            xmajorgrids,
            ymajorgrids,
            xmin=1,
            xmax=50,
            ymin=0,
            ymax=300,
            legend style={at={(0.03,0.97)},anchor=north west}
        ]

            \addplot[only marks, green] table [
            mark=*,
            col sep=semicolon,
            x={n},
            y={time},
            ]
                {async_messungen.csv};

            \addplot[thick, red] table [
            col sep=semicolon,
            x={n},
            y={time},
            y = {create col/linear regression={y={time},x={n}}},
            ]
                {async_messungen.csv};
            \xdef\slopeA{\pgfplotstableregressiona} %<-- might be handy occasionally
            \xdef\interceptA{\pgfplotstableregressionb}

            \addplot[only marks, blue] table [
            mark=*,
            col sep=semicolon,
            x={n},
            y={time},
            ]
                {async_messungen_server.csv};

            \addplot[thick, cyan] table [
            col sep=semicolon,
            x={n},
            y={time},
            y = {create col/linear regression={y={time},x={n}}},
            ]
                {async_messungen_server.csv};
            \xdef\slopeB{\pgfplotstableregressiona} %<-- might be handy occasionally
            \xdef\interceptB{\pgfplotstableregressionb}

            \addlegendentry{Server}
            \addlegendentry{$y=\pgfmathprintnumber{\slopeA} \cdot x \pgfmathprintnumber[print sign]{\interceptA}$}
            \addlegendentry{Remote}
            \addlegendentry{$y=\pgfmathprintnumber{\slopeB} \cdot x \pgfmathprintnumber[print sign]{\interceptB}$}
        \end{axis}
    \end{tikzpicture}
    \caption{Messungen bei asynchroner Implementierung}
    \label{fig:async-graph}
\end{figure}
Abbildung~\ref{fig:async-graph} zeigt uns, dass die asynchrone Implementierung linear skaliert.
In dieser Implementierung werden 10 Threads verwendet.
Damit haben wir, mit $\sim\Theta(n)$, eine gute Laufzeitkomplexität erreicht, sowie im Vergleich mit anderen Messungen aus dem Benchmark Portal auch eine gute absolute Laufzeit.
Deshalb beenden wir an dieser Stelle unsere Optimierungsversuche.


\subsection{DBMS}\label{subsec:dbms}
Außerdem werden weiter Optimierungsmöglichkeiten in Bezug auf das Datenbankmanagementsystem durchgeführt, um ein performanteres DBMS zu erreichen.
Dabei wurden verschiedene Konfigurationsänderungen durchgeführt, die nachfolgend genau beschrieben werden.\\
\\
MySQL allokiert Buffer und Caches, um die Leistung der Datenbankoperationen zu erhöhen.
Standardgemäß sind 512MB RAM für ein MySQL Server auf einer virtuellen Maschine zugewiesen.
Man kann die Leistung also erhöhen, indem man bestimmte Systemvariablen, die in Verbindung zu Buffer und Caches stehen, mehr Speicher zuweist.\\
\\
MySQL verwendet ein externes Speichersubsystem (Engine) namens InnoDB, dass die Schnittstelle zwischen dem DBMS und den Informationen darstellt.
InnoDB allokiert den gesamten Speicher beim Serverstart und verwendet dafür die malloc()-Operation.\\
\\
Die „innodb\_buffer\_pool\_size“-Variable steht für die buffer pool size und typischerweise sind 50\-70\% des Arbeitsspeichers dafür zugewiesen.
Hier werden Tabellen und Indexe gespeichert.
Zu Optimierungszwecken wurde die Eingabepufferung in der my.ini Datei geändert und geschaut, ob es einen merkbaren Unterschied macht.
Als erstes wurde die „innodb\_buffer\_pool\_size“ von 128MB, auf 2GB geändert und „innodb\_buffer\_log\_file\_size“ von 48MB auf 1GB, da es in der Beschreibung empfohlen worden ist, 25\%\-100\% des „buffer\_pool\_sizes“ zu reservieren.
Dementsprechend wurde 2GB aufgrund eines Forum Beitrags gewählt und erst später gemerkt, dass dadurch der gesamte Arbeitsspeicher der VM zugewiesen wurde.
Weshalb die Leistung des DMBS merkbar gesunken ist.
Daraufhin wurde 1GB für die Variable „innodb\_buffer\_pool\_size“ und 500MB für „innodb\_buffer\_log\_file\_size“ reserviert.
Diesmal konnte auch kein Leistungsverlust festgestellt werden, jedoch hat es auch zu keiner Verbesserung beigetragen.~\autocite{orcale-2022}~\autocite{stackexchange-2012}
