Um die ausführung der Statements zu beschleunigen, gibt es zwei Möglichkeiten: Performanteren Code oder eine Performanteres DBMS~. Im Folgenden sind zu beiden Möglichkeiten unsere Ansätze aufgeführt.

\subsection{Code}\label{subsec:code}
Schauen wir uns die 4 Methoden an, das Erstellen der Datenbanken, das Einfügen der Branches, das Einfügen der Accounts und das Einfügen der Automaten, so fällt schnell auf, dass keine der anderen Operationen einen signifikanten Zeitaufwand im Verhältnis zum Einfügen der Accounts benötigt.
Aus diesem Grund werden sich unsere Bemühungen bezüglich der Optimierungen im Code auf diese Teilaufgabe beziehen.
Hier ist uns vor allem eine Stellschraube in den Sinn gekommen: Die Anzahl der Statements.
Dazu haben wir zwei Möglichkeiten gefunden:
\begin{itemize}
    \item Das einfügen mehrerer Tupel mit einem Statement sowie
    \item das ausführen mehrerer Teilstatements in einem Statement (Batching).
\end{itemize}
Für n=1, also 100\_000 Tupel, sind die Messungen mit einer Logarithmischen Skala in Abbildung~\ref{fig:merged-statements-graph} dargestellt.
\begin{figure}[h!]
    \begin{tikzpicture}[baseline]
        \begin{axis}
        [
            small,
            width=\paperwidth/4,
            title={INSERT Statements},
            xlabel={Tupel pro Statement},
            ylabel={Zeit},
            y unit=\si{\second},
            scale only axis,
            xtick={1,10,100,1000,10000,100000},
            ytick={3,7,41,176,1647},
            yticklabels={3,7,41,176,1\_647},
            xmajorgrids,
            ymajorgrids,
            xmin=1,
            xmax=100000,
            ymin=0,
            ymax=2000,
            xmode=log,
            ymode=log,
        ]

            \addplot[only marks] table [
            mark=*,
            col sep=semicolon,
            x={duffConstant},
            y={time},
            ]
                {duff_messungen.csv};

            \addplot[thick, red] table [
            col sep=semicolon,
            x={duffConstant},
            y={time},
            y = {create col/linear regression={xmode=log,ymode=log, y={time},x={duffConstant}}},
            ]
                {duff_messungen.csv};
            \addlegendentry{$\log{y}=\pgfmathprintnumber{\pgfplotstableregressiona} \cdot \log{x} \pgfmathprintnumber[print sign]{\pgfplotstableregressionb}$}
        \end{axis}
    \end{tikzpicture}%
    \begin{tikzpicture}[baseline]
        \begin{axis}
        [
            small,
            width=\paperwidth/4,
            title={Batches},
            xlabel={Tupel pro Statement},
            ylabel={Zeit},
            y unit=\si{\second},
            scale only axis,
            xtick={1,10,100,1000,10000,100000},
            ytick={150,300,1500,2000},
            yticklabels={150,300,1\_500,2\_000},
            xmajorgrids,
            ymajorgrids,
            xmin=1,
            xmax=100000,
            ymin=0,
            ymax=2000,
            xmode=log,
            ymode=log,
            legend style={at={(0.97,0.6)},anchor=east}
        ]

            \addplot[only marks, blue] table [
            mark=*,
            col sep=semicolon,
            x={tupelsPerBatch},
            y={time},
            ]
                {batch_messungen.csv};
            \addlegendentry{Mit Autocommit}

            \addplot[only marks, green] table [
            mark=*,
            col sep=semicolon,
            x={tupelsPerBatch},
            y={time},
            ]
                {batch_no_autocommit_messungen.csv};
            \addlegendentry{Ohne Autocommit}
        \end{axis}
    \end{tikzpicture}
    \caption{Messungen bei unterteilung in verschieden viele Statements}
    \label{fig:merged-statements-graph}
\end{figure}
Schauen wir uns zunächst die Variante mit den vereinten INSERT Statements an, so fällt uns auf, dass die Messwerte annähernd auf der logarithmischen annäherung liegen.
Desto weniger Statements, desto schneller ist das Programm.
Im Vergleich dazu ist bei den Batches keine Konsistenz in den Messwerten zu erkennen.
Da jede Messung über 20 Minuten gedauert hat verzichten wir auf eine erneute Messung und schließen, dass beim Batching lediglich ein kleiner vorteil, unabhängig der anzahl der Batches, entsteht.
Es sind also die Commits, die Zeit benötigen.
Deaktivieren wir Autocommit so läuft auch die variante mit Batching deutlich schneller, auch wenn sie dennoch nicht mit den einzelnen Statements mithalten kann.
In diesem spezifischen Fall wollen wir uns also auf INSERT Statements mit vielen Tupeln festlegen.


\paragraph{Da} wir nun die Methodik kennen wollen wir uns ans Multithreading wagen.
\begin{figure}[h!]
    \center
    \begin{tikzpicture}[baseline]
        \begin{axis}
        [
            small,
            xlabel={n},
            ylabel={Zeit},
            y unit=\si{\second},
            scale only axis,
            xtick={1,10,20,50},
            ytick={3,41,143,405},
            yticklabels={3,41,143,405},
            xmajorgrids,
            ymajorgrids,
            xmin=1,
            xmax=50,
            ymin=0,
            ymax=500,
        ]

            \addplot[only marks] table [
            mark=*,
            col sep=semicolon,
            x={n},
            y={time},
            ]
                {async_messungen.csv};

            \addplot[thick, red] table [
            col sep=semicolon,
            x={n},
            y={time},
            y = {create col/linear regression={y={time},x={n}}},
            ]
                {async_messungen.csv};
            \addlegendentry{$y=\pgfmathprintnumber{\pgfplotstableregressiona} \cdot x \pgfmathprintnumber[print sign]{\pgfplotstableregressionb}$}
        \end{axis}
    \end{tikzpicture}
    \caption{Messungen bei asynchroner Implementierung}
    \label{fig:async-graph}
\end{figure}
Abbildung~\ref{fig:async-graph} zeigt uns, dass die Asynchrone Implementierung linear skaliert.
In dieser Implementierung werden 10 Threads verwendet.
Damit haben wir, mit $\sim\Theta(n)$, eine gute Laufzeitkomplexität erreicht sowie im Vergleich mit anderen Messungen aus dem Benchmark Portal auch eine gute absolute Laufzeit.
Deshalb beenden wir an dieser Stelle unsere Optimierungsversuche.


\subsection{DBMS}\label{subsec:dbms}
